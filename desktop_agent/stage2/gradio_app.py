import gradio as gr
import os
import cv2
import numpy as np
import time
import json
from modelscope import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor
from qwen_vl_utils import process_vision_info
import torch
from transformers import BitsAndBytesConfig
import warnings
import tempfile
from agent_prompt import ui_prompt

warnings.filterwarnings("ignore", category=UserWarning, module="torch.nn.functional")

# æŒ‡å®šæœ¬åœ°æ¨¡å‹æ–‡ä»¶å¤¹è·¯å¾„
model_path = "D:\\Downloads\\Model\\Qwen2.5-VL-3B-Instruct"

# 4-bité‡åŒ–é…ç½®
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_use_double_quant=True
)

# åŠ è½½æ¨¡å‹æ—¶æŒ‡å®šlocal_files_only=Trueï¼Œå¹¶åº”ç”¨é‡åŒ–é…ç½®
model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
    model_path,
    quantization_config=quantization_config,
    torch_dtype="auto",
    device_map="auto",
    local_files_only=True
)

# åŠ è½½åˆ†è¯å™¨æ—¶æŒ‡å®šlocal_files_only=True
processor = AutoProcessor.from_pretrained(
    model_path,
    local_files_only=True
)


def save_temp_image(image_np):
    """å°†numpyæ•°ç»„å›¾åƒä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶å¹¶è¿”å›è·¯å¾„"""
    temp_dir = tempfile.gettempdir()
    temp_path = os.path.join(temp_dir, f"temp_{int(time.time())}.jpg")
    cv2.imwrite(temp_path, cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR))
    return temp_path


def get_element_coordinates(image_np, instruction):
    """
    æ ¹æ®å›¾åƒå’Œè‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œè·å–UIå…ƒç´ çš„è¾¹ç•Œæ¡†åæ ‡
    """
    # å°†numpyæ•°ç»„ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
    image_path = save_temp_image(image_np)

    messages = [
        {
            "role": "system",  # ç³»ç»Ÿçº§æŒ‡ä»¤
            "content": ui_prompt
        },
        {
            "role": "user",
            "content": [
                {"type": "image", "image": image_path},
                {
                    "type": "text",
                    "text": instruction,
                },
            ],
        }
    ]
    # åœ¨æ¨ç†ä»£ç å‰æ·»åŠ è®¡æ—¶å¼€å§‹
    start_time = time.time()

    # Preparation for inference
    text = processor.apply_chat_template(
        messages, tokenize=False, add_generation_prompt=True
    )
    image_inputs, video_inputs = process_vision_info(messages)
    inputs = processor(
        text=[text],
        images=image_inputs,
        videos=video_inputs,
        padding=True,
        return_tensors="pt",
    )
    inputs = inputs.to("cuda")

    # Inference: Generation of the output
    generated_ids = model.generate(**inputs, max_new_tokens=128)
    generated_ids_trimmed = [
        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
    ]
    output_text = processor.batch_decode(
        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False
    )

    # åœ¨æ¨ç†ä»£ç åæ·»åŠ è®¡æ—¶ç»“æŸ
    end_time = time.time()
    print(f"æ¨ç†æ—¶é—´ï¼š{end_time - start_time}ç§’")
    print("æ¨¡å‹è¾“å‡º:", output_text)

    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    try:
        os.remove(image_path)
    except:
        pass

    # è§£æJSONæ ¼å¼çš„è¾“å‡º
    try:
        # å‡è®¾è¾“å‡ºæ˜¯ ```json [ { "bbox_2d": [x1, y1, x2, y2], "label": "label" } ] ``` æ ¼å¼
        json_str = output_text[0].strip('```json').strip()
        data = json.loads(json_str)

        if isinstance(data, list) and len(data) > 0:
            # æå–ç¬¬ä¸€ä¸ªå¯¹è±¡çš„bbox_2dåæ ‡
            coordinates = data[0].get("bbox_2d", None)
            if coordinates and len(coordinates) == 4:
                return coordinates
    except json.JSONDecodeError:
        print("æ¨¡å‹è¾“å‡ºä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼")

    return None


def visualize_coordinates(image_np, coordinates):
    """
    åœ¨åŸå›¾ä¸Šå¯è§†åŒ–æ˜¾ç¤ºè¾¹ç•Œæ¡†ï¼ˆç‚«é…·ç‰ˆï¼‰
    """
    if image_np is None:
        print("æ— æ³•åŠ è½½å›¾åƒï¼Œè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®")
        return None

    if not coordinates:
        print("æœªæ‰¾åˆ°æœ‰æ•ˆåæ ‡")
        return image_np

    # åˆ›å»ºå‰¯æœ¬
    image = image_np.copy()
    x1, y1, x2, y2 = coordinates

    # ========== 1. åŠ¨æ€å‘å…‰è¾¹æ¡† ==========
    border_color = (0, 255, 255)  # é’è‰²
    thickness = 3
    glow_size = 5

    # å‘å…‰æ•ˆæœï¼ˆå¤šå±‚æ¨¡ç³Šè¾¹æ¡†ï¼‰
    for i in range(glow_size, 0, -1):
        alpha = i / glow_size * 0.3  # é€æ˜åº¦é€’å‡
        overlay = image.copy()
        cv2.rectangle(overlay, (x1 - i, y1 - i), (x2 + i, y2 + i), border_color, thickness)
        image = cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0)

    # ========== 2. 3Dç«‹ä½“è¾¹æ¡† ==========
    # ä¸Šè¾¹å’Œå·¦è¾¹ç”¨äº®è‰²
    cv2.line(image, (x1, y1), (x2, y1), (100, 255, 100), thickness)
    cv2.line(image, (x1, y1), (x1, y2), (100, 255, 100), thickness)
    # ä¸‹è¾¹å’Œå³è¾¹ç”¨æš—è‰²
    cv2.line(image, (x1, y2), (x2, y2), (0, 150, 0), thickness)
    cv2.line(image, (x2, y1), (x2, y2), (0, 150, 0), thickness)

    # ========== 3. åŠ¨æ€æ ‡è®°ç‚¹ ==========
    corner_color = (255, 0, 255)  # å“çº¢è‰²
    corner_size = 10
    # å››ä¸ªè§’ç”»åœ†
    cv2.circle(image, (x1, y1), corner_size, corner_color, -1)
    cv2.circle(image, (x1, y2), corner_size, corner_color, -1)
    cv2.circle(image, (x2, y1), corner_size, corner_color, -1)
    cv2.circle(image, (x2, y2), corner_size, corner_color, -1)

    # ========== 4. ä¸­å¿ƒæ ‡è®° + åŠ¨ç”»æ•ˆæœ ==========
    center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2
    # è„‰å†²åœ†ç¯åŠ¨ç”»æ•ˆæœ
    pulse_radius = int(abs((time.time() % 1 - 0.5) * 20 + 15)) # 15-35ä¹‹é—´è„‰åŠ¨
    cv2.circle(image, (center_x, center_y), pulse_radius, (255, 255, 0), 2)

    # ========== 5. ä¿¡æ¯æ ‡ç­¾ ==========
    label = "DETECTED!"
    font = cv2.FONT_HERSHEY_SIMPLEX
    text_size = cv2.getTextSize(label, font, 0.7, 2)[0]
    # æ–‡å­—èƒŒæ™¯
    cv2.rectangle(image, (x1, y1 - 30), (x1 + text_size[0] + 10, y1), (50, 50, 220), -1)
    # æ–‡å­—
    cv2.putText(image, label, (x1 + 5, y1 - 10), font, 0.7, (255, 255, 255), 2)

    # ========== 6. åŒºåŸŸé«˜äº® ==========
    highlight = image.copy()
    mask = np.zeros_like(highlight)
    cv2.rectangle(mask, (x1, y1), (x2, y2), (255, 255, 255), -1)
    highlight = cv2.bitwise_and(highlight, mask)
    image = cv2.addWeighted(image, 0.7, highlight, 0.3, 0)

    return image


def process_ui_detection(image_np, instruction):
    """
    å¤„ç†UIæ£€æµ‹
    """
    coordinates = get_element_coordinates(image_np, instruction)
    result_image = visualize_coordinates(image_np, coordinates)
    return result_image, json.dumps({"coordinates": coordinates}) if coordinates else "æœªæ‰¾åˆ°æœ‰æ•ˆåæ ‡"


# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ–¼ï¸ UIå…ƒç´ æ£€æµ‹ç³»ç»Ÿ
    ä½¿ç”¨Qwen2.5-VLå¤šæ¨¡æ€æ¨¡å‹æ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤å®šä½UIå…ƒç´ 
    """)

    with gr.Row():
        with gr.Column():
            image_input = gr.Image(label="ä¸Šä¼ ç•Œé¢æˆªå›¾", type="numpy")
            instruction_input = gr.Textbox(
                label="æ£€æµ‹æŒ‡ä»¤",
                placeholder="ä¾‹å¦‚ï¼š'è¯·è¿”å›å¾®ä¿¡å›¾æ ‡çš„åæ ‡'",
                lines=2
            )
            run_btn = gr.Button("æ£€æµ‹å…ƒç´ ", variant="primary")

            gr.Examples(
                examples=[
                    [os.path.join(os.path.dirname(__file__), "img.png"), "è¯·å¯»æ‰¾Cursor"],
                    [os.path.join(os.path.dirname(__file__), "img.png"), "è¯·å¯»æ‰¾å¾®ä¿¡"]
                ],
                inputs=[image_input, instruction_input],
                label="ç¤ºä¾‹è¾“å…¥"
            )

        with gr.Column():
            image_output = gr.Image(label="æ£€æµ‹ç»“æœ", interactive=False)
            text_output = gr.Textbox(label="æ£€æµ‹ä¿¡æ¯", interactive=False)

    run_btn.click(
        fn=process_ui_detection,
        inputs=[image_input, instruction_input],
        outputs=[image_output, text_output]
    )

    gr.Markdown("""
### ä½¿ç”¨è¯´æ˜ï¼š
1. ä¸Šä¼ ç•Œé¢æˆªå›¾
2. è¾“å…¥è‡ªç„¶è¯­è¨€æŒ‡ä»¤æè¿°è¦å®šä½çš„å…ƒç´ 
3. ç‚¹å‡»"æ£€æµ‹å…ƒç´ "æŒ‰é’®
4. ç»“æœå°†æ˜¾ç¤ºæ£€æµ‹æ¡†å’Œåæ ‡ä¿¡æ¯

**æ³¨æ„**ï¼šé¦–æ¬¡è¿è¡Œéœ€è¦åŠ è½½æ¨¡å‹ï¼Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´
""")

# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    demo.launch(
        server_name="localhost",
        server_port=7860,
        share=False,
        show_error=True
    )